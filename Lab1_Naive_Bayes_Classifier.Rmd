---
editor_options:
  markdown:
    wrap: 72
---

# Probability and Statistics

# Lab Assignment 1: Naive Bayes Classifier

### *Andrii Yaroshevych, Dmytro Vasylkiv, Vitalii Petrychko*

## Introduction

During the past three weeks, you learned a couple of essential notions
and theorems, and one of the most important among them is the *Bayes
theorem*.

One of its applications is **Naive Bayes classifier**, which is a
probabilistic classifier whose aim is to determine which class some
observation probably belongs to by using the Bayes formula:
$$\mathsf{P}(\mathrm{class}\mid \mathrm{observation})=\frac{\mathsf{P}(\mathrm{observation}\mid\mathrm{class})\mathsf{P}(\mathrm{class})}{\mathsf{P}(\mathrm{observation})}$$

Under the strong independence assumption, one can calculate
$\mathsf{P}(\mathrm{observation} \mid \mathrm{class})$ as
$$\mathsf{P}(\mathrm{observation}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i), \qquad \mathsf{P}(\mathrm{observation} \mid \mathrm{class}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i \mid \mathrm{class}),$$
where $n$ is the total number of features describing a given
observation. Thus, $\mathsf{P}(\mathrm{class}|\mathrm{observation})$ now
can be calculated as

$$\mathsf{P}(\mathrm{class} \mid \mathrm{\mathrm{observation}}) = \mathsf{P}(\mathrm{class})\times \prod_{i=1}^{n}\frac{\mathsf{P}(\mathrm{feature}_i\mid \mathrm{class})}{\mathsf{P}(\mathrm{feature}_i)}\tag{1}$$

All the terms on the right-hand side can be estimated from the data as
respective relative frequencies;\
see [this
site](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/)
for more detailed explanations.

## Data description

-   **2 - fake news** This data set contains data of American news: a
    headline and an abstract of the article. Each piece of news is
    classified as fake or credible. The task is to classify the news
    from test.csv as credible or fake.



```{r Libraries loading, message=FALSE, warning=FALSE, results='hide'}
library(tidytext)
library(readr)
library(dplyr)
library(ggplot2)
```

## Instructions

-   The first step is data pre-processing, which includes removing
    punctuation marks and stop words

-   Represent each message as a bag-of-words

-   Using the training set, calculate all the conditional probabilities
    in formula (1)

-   Use those to predict classes for messages in the test set

-   Evaluate effectiveness of the classifier by calculating the
    corresponding metrics

-   Shortly summarize your work

-   Do not forget to submit both the (compiled) Rmd source file and the .html
    output

### Data pre-processing

-   Read the *.csv* data files.
-   Ð¡lear your data from punctuation or other unneeded symbols.
-   Clear you data from stop words. You don't want words as is, and, or
    etc. to affect your probabilities distributions, so it is a wise
    decision to get rid of them. Find list of stop words in the cms
    under the lab task.
-   Represent each test message as its bag-of-words.


```{r Load datasets}
test_path <- "data/2-fake_news/test.csv"
train_path <- "data/2-fake_news/train.csv"

train <- read.csv(file = train_path, stringsAsFactors = FALSE)
test <- read.csv(file = test_path, stringsAsFactors = FALSE)
```

```{r Load stopwords}
stop_words_file <- read_file("stop_words.txt")

stop_words <- strsplit(stop_words_file, split='\n')
stop_words <- stop_words[[1]]
```

```{r TidyText}
tidy_text <- unnest_tokens(train, 'splitted', 'Body', token="words", to_lower = TRUE) %>%
             filter(!splitted %in% stop_words)
```

### Data visualization

Top words in the dataset

```{r Words frequencies, message=FALSE, warning=FALSE}
fake_news <- tidy_text %>%
             filter(Label == "fake") %>%
             count(splitted, sort=TRUE) %>%
             top_n(15)

credible_news <- tidy_text %>%
                 filter(Label == "credible") %>%
                 count(splitted, sort=TRUE) %>%
                 top_n(15)

ggplot(fake_news, aes(x = n, y = reorder(splitted, n))) +
    geom_col() +
    labs(x = "Frequency", y = "Word", title = "Top 15 words in fake news") +
    theme_minimal()

ggplot(credible_news, aes(x = n, y = reorder(splitted, n))) +
    geom_col() +
    labs(x = "Frequency", y = "Word", title = "Top 15 words in credible news") +
    theme_minimal()
```

Chart representation of classes distribution

```{r Classes distibution, message=FALSE, warning=FALSE}
pie_chart <- tidy_text %>%
             count(Label, sort=TRUE)

ggplot(pie_chart, aes(x = "", y = n, fill = Label)) +
    geom_bar(width = 1, stat = "identity") +
    coord_polar("y", start = 0) +
    labs(x = "", y = "Count", title = "Classes distribution") +
    scale_fill_manual(aesthetics = "fill", values = c("darkolivegreen2", "coral1")) +
    theme_minimal()
```

## Classifier implementation

```{r Classifier implementation}
naiveBayes <- setRefClass("naiveBayes",

       fields = list(
         data = "data.frame",
         fake_data = "data.frame",
         credible_data = "data.frame",
         number_of_fake_news = "numeric",
         number_of_credible_news = "numeric",
         fake_news_prob = "numeric",
         credible_news_prob = "numeric",
         fake_news_word_count = "numeric",
         credible_news_word_count = "numeric",
         total_word_count = "numeric"
       ),

       methods = list(
                    fit = function(data)
                    {
                        data <<- data
                        fake_data <<- data %>% filter(Label=="fake") %>% count(splitted, sort=TRUE)
                        credible_data <<- data %>% filter(Label=="credible") %>% count(splitted, sort=TRUE)

                        number_of_fake_news <<- nrow(train %>% filter(Label=="fake"))
                        number_of_credible_news <<- nrow(train %>% filter(Label=="credible"))

                        fake_news_prob <<- number_of_fake_news/(number_of_fake_news + number_of_credible_news)
                        credible_news_prob <<- number_of_credible_news/(number_of_fake_news + number_of_credible_news)

                        fake_news_word_count <<- sum(fake_data$n)
                        credible_news_word_count <<- sum(credible_data$n)

                        total_word_count <<- nrow(data %>% distinct(splitted))
                    },

                    predict = function(message)
                    {
                        message <- tolower(message)
                        entries <- strsplit(message, split=" ")[[1]]
                        entries <- entries[!grepl("[[:punct:]]", entries)]
                        entries <- entries[!(entries %in% stop_words)]

                        result <- 1

                        for (word in entries) {
                            number_of_entries_fake <- ifelse(
                              word %in% fake_data$splitted,
                              fake_data %>% filter(splitted==word) %>% pull(n), 0)

                            fake_word_conditional_prob <- (number_of_entries_fake + 1)/
                              (fake_news_word_count + total_word_count)

                            number_of_entries_credible <- ifelse(
                              word %in% credible_data$splitted,
                              credible_data %>% filter(splitted==word) %>% pull(n), 0)

                            credible_word_conditional_prob <- (number_of_entries_credible + 1)/
                              (credible_news_word_count + total_word_count)

                            result <- result * (fake_word_conditional_prob/credible_word_conditional_prob)
                        }

                        result <- result * (fake_news_prob/credible_news_prob)

                        if (result > 1) {
                            return("fake")
                        } else {
                            return("credible")
                        }
                    },

                    score = function(test)
                    {
                         result <- data.frame(test)
                         result$PredictedLabel <- apply(result["Body"], MARGIN=1, .self$predict)

                         write.csv(result,'result.csv')
                         correct_values <- nrow(result %>% filter(result$Label == result$PredictedLabel))

                         return(correct_values/nrow(result))
                    }
))

model <- naiveBayes()
model$fit(tidy_text)
```

## Effectiveness of classifier

All calculations can be done using the `result.csv` file. The accuracy of the classifier is 93%.

Here we will use the actual and predicted labels to calculate all the metrics.

```{r Effectiveness of classifier}
result <- read.csv("result.csv", stringsAsFactors = TRUE)
```

```{r Confusion matrix}
confusion_matrix <- table(result$Label, result$PredictedLabel, dnn = c("Actual", "Predicted"))
```

```{r Accuracy}
accuracy <- sum(diag(confusion_matrix))/sum(confusion_matrix)
print(accuracy)
```

```{r Precision}
precision <- confusion_matrix[1,1]/sum(confusion_matrix[,1])
print(precision)
```

```{r Recall}
recall <- confusion_matrix[1,1]/sum(confusion_matrix[1,])
print(recall)
```

```{r F1 score}
f1_score <- 2 * (precision * recall)/(precision + recall)
print(f1_score)
```

Or, we can use the `caret` package to calculate all the metrics.

```{r, message=FALSE, warning=FALSE}
library(caret)
confusionMatrix(result$Label, result$PredictedLabel)
```

Visualization of the confusion matrix:

```{r Confusion matrix visualization}
library(ggplot2)

confusion_data <- as.data.frame(confusion_matrix)

ggplot(confusion_data, aes(x = Actual, y = Predicted, fill = Freq)) +
    geom_tile() +
    geom_text(aes(label = Freq), size = 3, color = "white") +
    labs(x = "Actual", y = "Predicted", title = "Confusion Matrix") +
    scale_fill_gradient(low = "grey", high = "darkgreen", name = "Frequency") +
    theme_minimal()
```


## Conclusions

Summarize your work by explaining in a few sentences the points listed
below.

-   Describe the method implemented in general. Show what are
    mathematical foundations you are basing your solution on.
-   List pros and cons of the method. This should include the
    limitations of your method, all the assumption you make about the
    nature of your data etc.
